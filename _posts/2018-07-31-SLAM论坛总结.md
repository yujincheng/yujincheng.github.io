---
layout: post
title: 浙江杭州第一届全国SLAM论坛总结
date: 2018-07-31
author: 阿金
cover: https://timgsa.baidu.com/timg?image&quality=80&size=b9999_10000&sec=1533006236329&di=0d780ef64b350e78f68735cfefadc951&imgtype=0&src=http%3A%2F%2Fimg.trustexporter.com%2F201709%2F29%2F111001721900644.jpg
tags: 生活
---

2018年七月28-七月29日，在浙江大学紫荆港校区举办了第一届全国SLAM论坛。我去听了所有的报告。

# 报告内容

## 浙江大学章国锋老师

主要介绍了他们实验室在SLAM方向的几个工作。其网站如下，http://www.zjucvg.net/

1. ENFT-SFM:Efficient Non-Consecutive Feature Tracking for Robust SFM

    主要解决的还是匹配的问题，尤其是存在帧不连续的情况下（运动过快、存在回环、多视频序列）。主要将图像匹配与描述各帧相似程度的协方差矩阵近些协同优化。

2. ENFT-SLAM：ENFT-based Large-Scale Monocular SLAM

    1. 对之前的工作做了实时性优化。采用视频分段的优化方法，先将视频分为少数几段，只对段间进行优化。之后越分越细。
    2. 在kitti等数据集上效果和ORB类似，但是在自建的回环和多视频数据集上远高于ORB的性能。

3. RDSLAM：Robust Monocular SLAM in Dynamic Environments

    动态调整、删除、替换 特征点。主要对动态场景有很好的效果。

4. RKSLAM：Robust Keyframe-based Monocular SLAM for Augmented Reality

    在特征较少的时候采用缩略图直接进行图像匹配。

总之，章老师负责介绍了自己实验室的几个工作。思路还是特征点为主、图像的直接匹配为辅的思路。因为特征点的物理意义，让基于特征的方法精度很高。

## 港科大沈劭劼老师

沈老师的工作非常有影响力。

他们组的[VINS-Mono](https://github.com/HKUST-Aerial-Robotics/VINS-Mono)在github上已经获得1k星。

### SLAM 步骤
沈老师把 SLAM 过程分成三个步骤：

----

<div class="mermaid">
graph LR
A[slam] --> B[state estimate] 
A --> C[mapping]
A --> D[6DoF tacking]
B -- 已经得到了较好的解决 --- E>找自己的位置]
C -- 最近正在解决 --- F>"对静态环境的(稠密)建图"]
D -- 还需要很多的工作才能解决 --- G>对动态物体的追踪]
</div>

----

由此可见，我们解决动态场景的目标是没什么大问题的。

### 单目建图

单目传感器是最便宜的传感器，所以基于单目可以尝试开发很多应用。

关于单目mapping（获取深度图）的工作。沈老师认为稠密重建大体可以分成三个步骤。

1. **获取多张图片作为输入**

2. **构建一个cost volume**。设计输入两张图片和一个可能的坐标变换，得到一个图片的损失函数。【就像双目视觉里全局优化一样，对比像素灰度差异获得最优坐标变换】

3. **寻找最优解**。利用各种优化方法来获得最优效果坐标变换。从而计算深度图。

### 关于神经网络的应用

在单目中，如果直接采用端到端的训练。直接获取深度图，会导致泛化能力下降，kitti上训练的数据集在室内场景没法用。

所以沈老师提出，用神经网络来构建 cost volume，用优化算法来恢复深度图。在kitti上的训练的模型可以直接在室内场景应用。

这个工作他会发表在 IROS 2018 上。

### 2D-3D 转换

还是基于单目视觉，为了减少计算量，并不需要每个像素都要进行优化，而且有些像素本来就没法进行优化（比如墙壁、地板）。

沈老师提出了一个对2D图像进行四叉树分割的方法，对文理少，变换少的区域减少计算，对复杂文理的区域进行更多的计算。

也会在 IROS 2018上发表。

## 阿里自动标定

感觉更像传感器校准的工作，非常工业风，就是从便宜、自动、够用入手。

## 上海交大邹丹平

主要介绍了两个工作

1. StructSLAM
2. StructVIO

思路很简单，之前只有特征点，在许多场景下会失效。所以引入了特征线。

引入特征（直）线之后又存在许多问题，比如一个曲线被分成多个直线。

提出优化方法解决这些问题。

## 自动化所申抒含

主要介绍场景重建。sfm，现在场景重建远远没有达到实时。（或者说也没什么实时地需求）。一般是对建筑进行比较精细的建模，建筑物也不会天天变，所以不算特别需要实时。

主要介绍的问题：在多个视角，不同远近采集到的数据，如何融合？

方法：先利用精细视角建图，然后将精细视角的图片网格化之后建立模型，将建好的模型在远端视角建立投影。之后融入远端信息。

这种方法可以介绍到我们多机系统中来。

## 工业界激光雷达

镭神智能来讲了下，主要介绍固态激光雷达就在路上了。以后激光雷达会很便宜，在 100美元左右。

## 工业界自动驾驶

### 图森未来

他们选择的是自动驾驶卡车，在港口、仓库区进行作业。现在基本上已经测试完成，正在推广。

他们采用的传感器很简单：6个摄像头，2个激光雷达。

因为他们的场景也相对来说比较清晰简单，所以能够快速开发完成。

### 环宇智行

他们主要是做的计算平台，包括 GPS、IMU、V2X模块，以及四个处理单元（英伟达显卡），还有对应的安全模块。

# 我的感想

1. 单纯做SLAM确实费些劲，听老师们讨论，在精度和泛化能力上，神经网络算法 短期内 无法超过基于特征点的方法。而且也没必要，因为现在的基于特征点方法已经很完备了。

2. 多传感器融合势在必行，现在纯视觉的SLAM算法很难部署。一旦加上 IMU，就可以把一个单目视觉系统较好得应用在无人机上。现在老师们做的方案，基本上都是 IMU + MONO 的融合。我们系统里，至少应该支持 IMU，我现在已经让 维遮 去看看怎么把 IMU 加入我们的系统中。